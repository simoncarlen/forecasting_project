{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in csv files with pollution data and clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in pollution data\n",
    "df_torkel_knutssong = pd.read_csv('../air_weather_data/torkel_knutssongatan.csv', sep=';', skiprows=11)\n",
    "df_hornsgatan = pd.read_csv('../air_weather_data/hornsgatan.csv', sep=';', skiprows=11)\n",
    "df_norr_malma = pd.read_csv('../air_weather_data/norr_malma.csv', sep=';', skiprows=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming relevant columns\n",
    "df_torkel_knutssong.rename(columns={'Slut':'Date', \n",
    "                                    'PM10 (107)':'PM$_{10}$, Torkel Knutssonsgatan', \n",
    "                                    'PM2.5 (102)':'PM$_{2.5}$, Torkel Knutssonsgatan',\n",
    "                                    'NO2 (105)':'NO$_2$, Torkel Knutssonsgatan'}, \n",
    "                                    inplace=True)\n",
    "\n",
    "df_hornsgatan.rename(columns={'Slut':'Date',\n",
    "                              'PM10 (116)':'PM$_{10}$, Hornsgatan',\n",
    "                              'PM2.5 (111)':'PM$_{2.5}$, Hornsgatan'}, \n",
    "                              inplace=True)\n",
    "\n",
    "df_norr_malma.rename(columns={'Slut':'Date',\n",
    "                              'PM10 (291)':'PM$_{10}$, Norr Malma',\n",
    "                              'PM2.5 (295)':'PM$_{2.5}$, Norr Malma'}, \n",
    "                              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelevant columns\n",
    "df_torkel_knutssong.drop('Start', axis=1, inplace=True)\n",
    "df_hornsgatan.drop(['Start', 'NO2 (115)'], axis=1, inplace=True)\n",
    "df_norr_malma.drop(['Start', 'NO2 (293)'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change date columns to pandas datetime format and make it index column\n",
    "df_torkel_knutssong['Date'] = pd.to_datetime(df_torkel_knutssong['Date'], format = '%Y-%m-%d %H:%M')\n",
    "df_torkel_knutssong = df_torkel_knutssong.set_index('Date') \n",
    "\n",
    "df_hornsgatan['Date'] = pd.to_datetime(df_hornsgatan['Date'], format = '%Y-%m-%d %H:%M')\n",
    "df_hornsgatan = df_hornsgatan.set_index('Date') \n",
    "\n",
    "df_norr_malma['Date'] = pd.to_datetime(df_norr_malma['Date'], format = '%Y-%m-%d %H:%M')\n",
    "df_norr_malma = df_norr_malma.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy of torkel knutssong dataframe and merge one at a time\n",
    "df_pollution = df_torkel_knutssong[:]\n",
    "df_pollution = df_pollution.merge(df_hornsgatan, on='Date')\n",
    "df_pollution = df_pollution.merge(df_norr_malma, on='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in weather data and clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../air_weather_data/'\n",
    "\n",
    "temperature = pd.read_csv(path + 'temperature.csv', sep=';', header = 2, encoding='latin')\n",
    "pressure = pd.read_csv(path + 'pressure.csv', sep=';', header = 2, encoding='latin')\n",
    "relative_humidity = pd.read_csv(path + 'relative_humidity.csv', sep=';', header = 2, encoding='latin')\n",
    "precipitation = pd.read_csv(path + 'precipitation.csv', sep=';', header = 2, encoding='latin')\n",
    "solar_radiation = pd.read_csv(path + 'solar_radiation.csv', sep=';', header = 2, encoding='latin')\n",
    "wind_speed = pd.read_csv(path + 'wind_speed.csv', sep=';', header = 2, encoding='latin')\n",
    "\n",
    "# make list with dataframes\n",
    "dframes = []\n",
    "dframes += [temperature, pressure, relative_humidity, precipitation, solar_radiation, wind_speed]\n",
    "column_names = ['Temperature', \n",
    "                'Atmospheric pressure', \n",
    "                'Relative humidity', \n",
    "                'Precipitation',\n",
    "                'Solar radiation',\n",
    "                'Wind speed']\n",
    "\n",
    "# remove unnecessary columns, turn date into index\n",
    "i = 0\n",
    "for df in dframes:\n",
    "    df.drop(df.columns[[3,4,5,6]], axis=1, inplace=True)\n",
    "    df.insert(0, 'Date', df['Datum'] + ' ' + df['Kl']) # insert a date column with date and hour\n",
    "    df.drop(['Datum', 'Kl'], axis=1, inplace=True) # drop columns Datum and Kl\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format = '%y-%m-%d %H:%M') # change date column to datetime format\n",
    "    dframes[i].columns.values[1] = column_names[i]\n",
    "    df.set_index('Date', inplace=True) # set date as index column\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = dframes[0]\n",
    "# merge all dataframes\n",
    "df_weather = df_weather.merge(dframes[1], on='Date')\n",
    "df_weather = df_weather.merge(dframes[2], on='Date')\n",
    "df_weather = df_weather.merge(dframes[3], on='Date')\n",
    "df_weather = df_weather.merge(dframes[4], on='Date')\n",
    "df_weather = df_weather.merge(dframes[5], on='Date')\n",
    "\n",
    "df_weather;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge pollution and weather dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge weather and pollution data\n",
    "# df_pollution_weather = df.merge()\n",
    "df_final = df_pollution.merge(df_weather, on='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make cosine and sine signals for day, week, and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "# sine and cosine of day, week, and year to capture seasonality of pollution data\n",
    "def add_sine_cosine(df):\n",
    "    # getting datetime columns and converting to seconds\n",
    "    timestamp_s = df.index.map(pd.Timestamp.timestamp)\n",
    "    day = 24*60*60\n",
    "    week = 7*day\n",
    "    year = (365.2425)*day\n",
    "    df['Sine day'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "    df['Cosine day'] = np.cos(timestamp_s * (2 * np.pi / day))    \n",
    "    df['Sine week'] = np.sin(timestamp_s * (2 * np.pi / week))\n",
    "    df['Cosine week'] = np.cos(timestamp_s * (2 * np.pi / week))\n",
    "    df['Sine year'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "    df['Cosine year'] = np.cos(timestamp_s * (2 * np.pi / year))\n",
    "    return df\n",
    "\n",
    "# apply above function to df_final\n",
    "df_final = add_sine_cosine(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save final dataset to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('../air_weather_data/pollution_and_weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a0afe78b3ebe22049d3d74ba655a4a5f799767e6308d99c3f84aabb51861a5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
