{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "df_NO2 = pd.read_csv('../air_weather_data/NO2_all_stations_cleaned.csv')\n",
    "df_NO2['date'] = pd.to_datetime(df_NO2['date'], format = '%Y-%m-%d %H:%M') # change time column to pandas datetime\n",
    "df_NO2 = df_NO2.set_index('date') # date column as index\n",
    "\n",
    "df_weather = pd.read_csv('../air_weather_data/metdata.csv')\n",
    "df_weather['date'] = pd.to_datetime(df_weather['date'], format = '%Y-%m-%d %H:%M') # change time column to pandas datetime\n",
    "df_weather = df_weather.set_index('date') # date column as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace zero and negative with NaNs and interpolate data\n",
    "df_NO2[df_NO2 <= 0] = np.NaN\n",
    "df_NO2.interpolate(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, val, and test sets\n",
    "df_NO2_train = df_NO2['2016-01-01 00:00':'2019-01-01 00:00']\n",
    "df_NO2_val = df_NO2['2019-01-01 01:00:00':'2020-01-01 00:00:00']\n",
    "df_NO2_test = df_NO2['2021-01-25 16:00:00':]\n",
    "\n",
    "df_weather_train = df_weather['2016-01-01 00:00':'2019-01-01 00:00']\n",
    "df_weather_val = df_weather['2019-01-01 01:00:00':'2020-01-01 00:00:00']\n",
    "df_weather_test = df_weather['2021-01-25 16:00:00':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index needed later\n",
    "index_train = df_NO2_train.index \n",
    "index_val = df_NO2_val.index\n",
    "index_test = df_NO2_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_NO2_train.merge(df_weather_train, on='date')\n",
    "df_val = df_NO2_val.merge(df_weather_val, on='date')\n",
    "df_test = df_NO2_test.merge(df_weather_test, on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input variables used in robust regression model\n",
    "stations = ['NO$_2$, Stockholm Torkel Knutssonsgatan',\n",
    "            'NO$_2$, Stockholm Hornsgatan 108 ',\n",
    "            'NO$_2$, Stockholm SveavÃ¤gen 59 ',\n",
    "            'NO$_2$, Stockholm E4/E20 Lilla Essingen',\n",
    "            'Temperature', \n",
    "            'Relative humidity', \n",
    "            'Precipitation', \n",
    "            'Solar radiation',\n",
    "            'Wind speed',\n",
    "            'Sine day', \n",
    "            'Cosine day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create y and X matrix for train, val, and test sets\n",
    "y_train = df_train['NO$_2$, Stockholm Torkel Knutssonsgatan']\n",
    "X_train = df_train[stations]\n",
    "\n",
    "y_val = df_val['NO$_2$, Stockholm Torkel Knutssonsgatan']\n",
    "X_val = df_val[stations]\n",
    "\n",
    "y_test = df_test['NO$_2$, Stockholm Torkel Knutssonsgatan']\n",
    "X_test = df_test[stations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# two scalers, one for X and on for y\n",
    "scaler1 = MinMaxScaler() \n",
    "scaler2 = MinMaxScaler()\n",
    "\n",
    "# normalize train set\n",
    "X_train = scaler1.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=stations)\n",
    "X_train.insert(0, 'date', index_train)\n",
    "X_train.set_index('date', inplace=True)\n",
    "\n",
    "y_train = scaler2.fit_transform(y_train.to_frame())\n",
    "y_train = pd.DataFrame(y_train, columns = ['NO$_2$, Torkel Knutssonsgatan'])\n",
    "y_train.insert(0, 'date', index_train)\n",
    "y_train.set_index('date', inplace=True)\n",
    "\n",
    "# normalize validation set\n",
    "X_val = scaler1.transform(X_val) # fit is not used here to only use statistics from train data\n",
    "X_val = pd.DataFrame(X_val, columns=stations)\n",
    "X_val.insert(0, 'date', index_val)\n",
    "X_val.set_index('date', inplace=True)\n",
    "\n",
    "y_val = scaler2.transform(y_val.to_frame()) # fit is not used here to only use statistics from train data\n",
    "y_val = pd.DataFrame(y_val, columns = ['NO$_2$, Torkel Knutssonsgatan'])\n",
    "y_val.insert(0, 'date', index_val)\n",
    "y_val.set_index('date', inplace=True)\n",
    "\n",
    "# normalize test set (except y which is kept as it is since we want to predict on original scale)\n",
    "X_test = scaler1.transform(X_test) # not fit here to use statistics from train data\n",
    "X_test = pd.DataFrame(X_test, columns=stations)\n",
    "X_test.insert(0, 'date', index_test)\n",
    "X_test.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26293,), (26293,))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = X_train.iloc[:,0].values\n",
    "np.shape(data[:-12]), np.shape(data[12:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`sampling_rate` must be lower than the length of the data. Received: sampling_rate=1, for data of length 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m input_data \u001b[39m=\u001b[39m data[:\u001b[39m-\u001b[39m\u001b[39m12\u001b[39m], \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m targets \u001b[39m=\u001b[39m data[\u001b[39m12\u001b[39m:],\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mpreprocessing\u001b[39m.\u001b[39;49mtimeseries_dataset_from_array(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     input_data,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     targets,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     sequence_length\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     sampling_rate\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X30sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m dataset:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X30sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   inputs, targets \u001b[39m=\u001b[39m batch\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/DL/lib/python3.10/site-packages/keras/preprocessing/timeseries.py:171\u001b[0m, in \u001b[0;36mtimeseries_dataset_from_array\u001b[0;34m(data, targets, sequence_length, sequence_stride, sampling_rate, batch_size, shuffle, seed, start_index, end_index)\u001b[0m\n\u001b[1;32m    168\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`sampling_rate` must be higher than 0. Received: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    169\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39msampling_rate=\u001b[39m\u001b[39m{\u001b[39;00msampling_rate\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m sampling_rate \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data):\n\u001b[0;32m--> 171\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`sampling_rate` must be lower than the length of the \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    172\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata. Received: sampling_rate=\u001b[39m\u001b[39m{\u001b[39;00msampling_rate\u001b[39m}\u001b[39;00m\u001b[39m, for data \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    173\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mof length \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m sequence_stride \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    175\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`sequence_stride` must be higher than 0. Received: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    176\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39msequence_stride=\u001b[39m\u001b[39m{\u001b[39;00msequence_stride\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: `sampling_rate` must be lower than the length of the data. Received: sampling_rate=1, for data of length 1"
     ]
    }
   ],
   "source": [
    "input_data = data[:-12], \n",
    "targets = data[12:],\n",
    "dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    input_data,\n",
    "    targets,\n",
    "    sequence_length=1,\n",
    "    sampling_rate=1)\n",
    "for batch in dataset:\n",
    "  inputs, targets = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    X_test.values[:-12], \n",
    "    y_test.values[12:],\n",
    "    sequence_length=12)\n",
    "\n",
    "dataset_val = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    X_val.values[:-12], \n",
    "    y_val.values[12:],\n",
    "    sequence_length=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples shape: (128, 12, 11)\n",
      "targets shape: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for samples, targets in dataset:\n",
    "    print(\"samples shape:\", samples.shape)\n",
    "    print(\"targets shape:\", targets.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/simoncarlen/opt/miniconda3/envs/DL/lib/python3.10/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/simoncarlen/opt/miniconda3/envs/DL/lib/python3.10/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/simoncarlen/opt/miniconda3/envs/DL/lib/python3.10/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/simoncarlen/opt/miniconda3/envs/DL/lib/python3.10/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/simoncarlen/opt/miniconda3/envs/DL/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/simoncarlen/opt/miniconda3/envs/DL/lib/python3.10/site-packages/keras/layers/core/dense.py\", line 139, in build\n        raise ValueError('The last dimension of the inputs to a Dense layer '\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" (type Sequential).\n    \n    The last dimension of the inputs to a Dense layer should be defined. Found None. Full input shape received: (None, None)\n    \n    Call arguments received:\n      â¢ inputs=tf.Tensor(shape=(None, None, 11), dtype=float64)\n      â¢ training=True\n      â¢ mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X41sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m early_stopping \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X41sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                                                   patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X41sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                                   mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X41sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m dense\u001b[39m.\u001b[39mcompile(loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mMeanSquaredError(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X41sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m               optimizer\u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X41sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[tf\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mMeanSquaredError()])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X41sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m history_dense \u001b[39m=\u001b[39m dense\u001b[39m.\u001b[39;49mfit(dataset, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X41sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                           epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X41sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                           validation_data\u001b[39m=\u001b[39;49mdataset_val,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simoncarlen/Desktop/forecasting_project/jupyter_notebooks/dense_DL_model_NO2.ipynb#X41sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                           callbacks \u001b[39m=\u001b[39;49m [early_stopping])\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/DL/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/DL/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1129\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   1130\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1131\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/simoncarlen/opt/miniconda3/envs/DL/lib/python3.10/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/simoncarlen/opt/miniconda3/envs/DL/lib/python3.10/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/simoncarlen/opt/miniconda3/envs/DL/lib/python3.10/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/simoncarlen/opt/miniconda3/envs/DL/lib/python3.10/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/simoncarlen/opt/miniconda3/envs/DL/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/simoncarlen/opt/miniconda3/envs/DL/lib/python3.10/site-packages/keras/layers/core/dense.py\", line 139, in build\n        raise ValueError('The last dimension of the inputs to a Dense layer '\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" (type Sequential).\n    \n    The last dimension of the inputs to a Dense layer should be defined. Found None. Full input shape received: (None, None)\n    \n    Call arguments received:\n      â¢ inputs=tf.Tensor(shape=(None, None, 11), dtype=float64)\n      â¢ training=True\n      â¢ mask=None\n"
     ]
    }
   ],
   "source": [
    "dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1),\n",
    "    tf.keras.layers.Reshape([1, -1]),\n",
    "\n",
    "])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  patience=5,\n",
    "                                                  mode='min')\n",
    "\n",
    "dense.compile(loss = tf.losses.MeanSquaredError(),\n",
    "              optimizer= tf.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=[tf.metrics.MeanSquaredError()])\n",
    "\n",
    "history_dense = dense.fit(dataset, \n",
    "                          epochs=30, \n",
    "                          validation_data=dataset_val,\n",
    "                          callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense.evaluate(dataset_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a0afe78b3ebe22049d3d74ba655a4a5f799767e6308d99c3f84aabb51861a5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
