%General implementation of the stategy here before going into details about sources, preprocessing, hyperparameter tuning etc, ... Perhaps also a pic?
The major steps of the implemented workflow were as follows; 

Detailed descriptions of each step in the process are given in subsequent sections

%is shown in Figure \ref{fig:dataflow}. Historical air pollution data from several monitoring stations, together with meteorological data from one station, was retrieved, preprocessed (with some features engineered), and divided into data windows. Three deep learning models (feed forward neural network, RNN, and LSTM) were trained and tested for short-term predictions (one hour ahead) of PM$_{10}$ for one station at Torkel Knutssongatan (measuring urban background levels, see Table \ref{tab:stations}). As baseline models for comparison, multiple linear regression and ARIMA were used. Detailed descriptions of each step in the process are given in subsequent sections. 

%\begin{figure}[htbp]
%\begin{center}
%\makebox[\textwidth][c]{\includegraphics[width=1\textwidth]{workflow}}
%\caption{Implemented workflow.}
%\label{fig:dataflow}
%\end{center}
%\end{figure}

\section{Data retrieval and preprocessing}
\label{chap:dataprocesschap}

\subsection{Data sources}
\label{sec:data-sources}

Air pollution data was retrieved from the Swedish Meteorological and Hydrological Institute's (SMHI) centralized database for air quality measurements \cite{smhi-luftmatningar}. This data is part of the national and regional environmental monitoring of Sweden, a program coordinated and funded by the Swedish Environmental Protection Agency (Swedish EPA) and the Swedish Agency for Marine and Water Management. There are in total ten different program areas, of which air is one, and all data are licensed under CC0 and therefore freely accessible to the public \cite{naturvardsverket-miljodata}. For the national air monitoring (under Swedish EPA's responsibility), SMHI acts as a national data host and stores (quality checked) historical data reported yearly from municipalities in Sweden \cite{smhi-luftmatningar}.

In Stockholm County, there are 19 stationary monitoring sites \cite{slb-matningar}, and initially, data from each site was considered. However, many stations have irregular data series, and not all stations measure the same set of pollutants. Due to this, data from three sites with hourly measurements of PM$_{10}$ and PM$_{2.5}$ (in \textmugreek g/m$^3$) for the time period 2016-01-01 to 2022-01-01 was chosen, giving a total of 52,609 data points. For the station where PM predictions subsequently were to be made (Torkel Knutssonsgatan), hourly data of NO$_2$ was also included. As described in section \ref{air-pollution-stockholm}, SLB-analys also monitor several weather parameters, and hourly measurements of temperature (in $^\circ$C), precipitation (mm), atmospheric pressure (hPa), relative humidity (as \%), solar radiation (W/m$^2$), and wind speed (m/s) was also included from the station at Torkel Knutssonsgatan. The meteorological data were downloaded from SLB-analys' webpage \cite{slb-analys-meteorologi}. 

In general, air pollution monitoring can be classified by the area surrounding the station (rural, rural-regional, rural-remote, suburban, and urban), and by the predominant emission sources (background, industrial, or traffic) \cite{smhi-luftmatningar}. The chosen stations included data from both traffic and background monitoring, in urban as well as rural-regional areas. Information about the stations from which data was included is given in Table \ref{tab:stations}. 

% STATIONS TABLE
% ##############
\begin{table}[]
\centering
\caption{Monitoring stations in Stockholm County.}
\label{tab:stations}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}llllll@{}}
\toprule
Station                         & Station code & Longitude & Latitude  & Type of monitoring                                                   & Parameters                                                                                             \\ \midrule
Norrt√§lje, Norr Malma           & 18643        & 18.631313 & 59.832382 & \begin{tabular}[c]{@{}l@{}}Rural-Regional \\ Background\end{tabular} & PM$_{10}$, PM$_{2.5}$                                                                                  \\ \midrule
Stockholm, Hornsgatan 108       & 8780         & 18.04866  & 59.317223 & Urban Traffic                                                        & PM$_{10}$, PM$_{2.5}$                                                                                  \\ \midrule
Stockholm, Torkel Knutssonsgatan & 8781         & 18.057808 & 59.316006 & Urban background                                                     & \begin{tabular}[c]{@{}l@{}}PM$_{10}$, PM$_{2.5}$, NO$_2$, \\ meteorological \\ parameters\end{tabular} \\ \bottomrule
\end{tabular}%
}
\end{table}
% ##############

\subsection{Data preprocessing}

Time series plots of the raw PM$_{10}$ and PM$_{2.5}$ data are shown in Fig.\ \ref{fig:time_series_plots}. 
%(station-wise, with PM$_{10}$ and PM$_{2.5}$ values in the left and right subplots, respectively). 
As can be seen e.g.\ in Fig.\ \ref{fig:time_series_plots}c and Fig.\ \ref{fig:time_series_plots}e, some stations had short episodes with missing data, and linear interpolation was used to fill in these missing data points. However, for the PM$_{2.5}$ data at Torkel Knutssonsgatan (Fig.\ \ref{fig:time_series_plots}b), due to the rather big gap seen at the beginning of 2019, a train-test split was done to entirely avoid this time period (see below). Moreover, before use in any of the models, all data was normalized (i.e., scaled to standard units). 

\begin{figure}[h]
\centering
\makebox[\textwidth][c]{\includegraphics[width=1.1\textwidth]{../plots/time_series_plots}}
\caption{Time series plots for PM$_{10}$ and PM$_{2.5}$.}
\label{fig:time_series_plots}
\end{figure}

%\paragraph{Feature engineering}
%From the meteorological data, wind vectors ($u$ and $v$) were derived from wind direction and wind speed, as wind vectors are more suitable model inputs \cite{tensorflow-timeseries}. After converting wind direction values to radians, $u$ and $v$ were obtained in the following way $$ u = ws * cos(\theta)$$ $$v = ws * sin(\theta)$$ where $ws$ denote wind speed and $\theta$ is the wind direction (in radians). 
In Figure \ref{fig:time_series_plots}, yearly periodicity in the data can be seen, especially for PM$_{10}$ where levels tend to be higher during spring. Daily and weekly periodicity is also expected since traffic intensity varies throughout the day and week. The meteorological variables such as temperature, solar radiation, etc.\ also have periodicity. To account for this, timestamps were converted to temporal variables as sine and cosine signals for day, week, and year. For example, the sine and cosine signals for day were calculated in the following way

$$ \text{sine day = sin} \Big (\text{timestamp} \cdot \frac{2\pi}{86,400} \Big)$$
$$ \text{cosine day = cos} \Big (\text{timestamp} \cdot \frac{2\pi}{86,400} \Big)$$
where timestamp is in seconds (and with 86,400 seconds in 24 hours, dividing by this term is necessary). The calculations were done similarly for week and year, except for the term in the denominator which instead was set to seconds per week and seconds per year, respectively. 
%The transformations were done so that the sine and cosine functions oscillate between zero and one. 
The temporal variables for day in a 24 hour time window are shown in Figure \ref{fig:time_sine_cos}.

\begin{figure}[h] 
\begin{center}
%\makebox[\textwidth][c]{\includegraphics[width=.585\textwidth]{../plots/time_signals}}
\includegraphics{../plots/time_signals}
\caption{Temporal variables for day as sine and cosine signals.}
\label{fig:time_sine_cos}
\end{center}
\end{figure}
%\paragraph{Sliding windows}

Sliding windows from the data were also created. The sliding window approach is used for time-series forecasting where windows (or sequences of certain lengths, also called frames) are extracted from the input data \cite{Arsov2021, Gilik2021}. In each window, there are two "sub-windows"; the input window and the target window, and the target window is offset by some amount of time from the input window. For example, as shown in Figure \ref{fig:sliding-window}, the total window length is nine time steps, and the first eight time steps is the input window used to predict the target window (in this case having a length of one) one time step in the future. After extracting a data sequence, the window slides to the right one (or more) steps and extracts the next sequence. This is continued until time step $n$ at which point all the data have been processed. 
In this work, input windows of different lengths were tested to make short-term predictions for a target window with a length of one (more details are given in section \ref{sec:tuning} below). 

 \begin{figure}[h]
\begin{center}
\includegraphics{sliding-windows}
\caption{Sliding window approach for time-series data.}
\label{fig:sliding-window}
\end{center}
\end{figure}

%In this work, input window lengths were set to 12 hr, and predictions were made 1 hr, 6 hr, and 12 hr in the future (giving total window lengths of 13 hr, 18 hr, and 24 hr, respectively). Moreover, single-output models predicting PM levels at one urban background station (Torkel Knutssongatan),  as well as multi-output models predicting PM levels at all urban traffic stations, were tested.

%In this work, the window lengths were set to 12 hours, and both single time-step predictions (target windows of length one) and multi-time-step predictions (target windows of length $n$) were tested. Moreover, prediction models giving both single-outputs (the target value at one monitoring station) as well as multi-outputs (target value at all stations) were constructed.

%\paragraph{Train-test split} Lastly, the data was split into training (60\%), validation (20\%), and test (20\%) sets, where the validation set was used for hyperparameter tuning (described in more detail in section \ref{sec:tuning}). Being sequence data, the sampling was done consecutively, without random shuffling, so that order information would be preserved \cite{Gilik2021}. 
\paragraph{Train-test split} Lastly, the data was split into training, validation, and test sets, where the validation set was used for hyperparameter optimization. The test set was taken as the most recent year of data (from 2019-09-16 to 2020-09-16), the validation set was taken as the year prior to the test data (2018-09-16 to 2019-09-16), and the remaining data was used for training (2016-01-01 to 2018-09-16). This split is motivated by the fact that the data is in the form of time-series, where each observation has a specific time-stamp and where successive observations are (in this case) positively autocorrelated \cite{Brockwell2016}.

%Being sequence data, the sampling was done consecutively, without random shuffling, so that order information would be preserved 

%/Users/simoncarlen/desktop/thesis/data_and_code/plots/PM10_2016_2020_2

%\begin{figure}[h]
%\centering
%\makebox[\textwidth][c]{\includegraphics[width=1.1\textwidth]{../plots/time_series_plots}}
%\caption{Time series plots for PM$_{10}$ and PM$_{2.5}$.}
%\label{fig:time_series_plots}
%\end{figure}

\section{Hyperparameter tuning and search}
\label{sec:tuning}

The Keras Tuner library \cite{omalley2019kerastuner} was used to find the best set of hyperparameters for each model (except for the MLR and ARIMA models used as baseline). 
%Hyperparameters at both the model architecture-level as well as the input data-level were included in the search space. More specifically, at the input data-level, the width of the windows were set to 3 h, 6 h, or 12 h, and the models were fit with the different versions of the input data. 
More specifically, the following hyperparameters were tuned:

\begin{itemize}
\item Number of layers (up to five were tested)
\item Number of units per layer (in the range [32, 512] with step size set to 32)
\item Learning rate (sampled uniformly in the range [0.0001, 0.01])
\item Number of epochs 
\end{itemize} 

%For some models, a dropout layer (with rates in the range [0, 0.3] and step size set to 0.05) was also tested.
For the hyperparameter search, Bayesian optimization was used as tuner. (The Bayesian optimization tuner tries to predict which hyperparameters that are likely to improve the model given previous results \cite{omalley2019kerastuner}). The motivation for this choice is the large number of possible hyperparameter combinations, making it infeasible to test all of them within a reasonable amount of time. Instead, it was assumed that the tuner after 75 trials would find some optimal set of hyperparameters. 
The hyperparameter search was done in total three times for every model; one search each was performed for data input windows of different sizes, namely 8 h, 16 h, and 24 h. After completing the search, the number of epochs for each model were tuned, and all models were re-trained and evaluated on the validation and test data. 


%, the models were re-trained on the training set plus the validation set, and performance on the test set was recorded. Again, with three different window sizes tested, three versions per model were obstained. All predictions were made for PM$_{10}$ one hour ahead for the station at Torkel Knutssongatan (measuring urban background levels in the center of Stockholm).
